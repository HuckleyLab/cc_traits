{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn version:  0.18  (need > 0.18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn import __version__\n",
    "print(\"Sklearn version: \", __version__, \" (need >= 0.18)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Experiments <small>on alpine plants data</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete:\n",
      "Number of Entries: 20\n",
      "Cols removed: set()\n",
      "# Rows Removed: 113\n"
     ]
    }
   ],
   "source": [
    "DROP_FEATS = 0 # 0 no, 1 yes. 0 = drop rows with N/A. 1 = drop columns with N/A\n",
    "\n",
    "plants_master = pd.read_csv(\"plants5.csv\")\n",
    "\n",
    "\n",
    "drop_features = [\"Taxon\",\n",
    "                 \"migr_sterr_m\", \n",
    "                 \"shift + 2SE\", \n",
    "                 'signif_shift',\n",
    "                 \"signif_shift2\",\n",
    "                 \"dispmode01\",\n",
    "                 \"DispModeEng\", ## what is this\n",
    "                 \"shift + 2SE\",\n",
    "                ]\n",
    "\n",
    "categorical_features = [\"oceanity\", \"dispersal_mode\", \"BreedSysCode\", \"Grime\"]\n",
    "\n",
    "# one-hot encoding for categorical features:\n",
    "plants = pd.get_dummies(plants_master, columns=categorical_features)\n",
    "\n",
    "# drop features we don't want\n",
    "features = plants.drop(drop_features, axis=1)\n",
    "\n",
    "# drop features with n/a or NaN\n",
    "beforenona = set(features.columns.values)\n",
    "## axis = 1 drops columns with any NAs, axis = 0 drops rows with any NAs\n",
    "features = features.dropna(axis=DROP_FEATS)\n",
    "afternona  = set(features.columns.values)\n",
    "\n",
    "# extract response variable from trimmed data\n",
    "target   = features[\"migration_m\"]\n",
    "features.drop([\"migration_m\"], inplace=True, axis=1)\n",
    "\n",
    "print(\"Processing complete:\")\n",
    "print(\"Number of Entries: \" + str(len(features)))\n",
    "print(\"Cols removed: \" + str((beforenona-afternona)))\n",
    "print(\"# Rows Removed: \" + str(len(plants_master) - len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_features = StandardScaler().fit(features).transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) RFR with Cross Validation and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "[[-1.22474487  1.         -2.18555181 -0.13018891  2.5413099  -1.73916398\n",
      "   0.87093638  2.18306339 -0.5        -0.59342385 -0.63197941 -0.54575406\n",
      "  -0.63579539 -0.59190877 -0.18304938 -0.09192978 -0.1182005  -0.96252004\n",
      "  -0.35805744 -0.67800972 -1.57525452 -0.88041408 -0.65672674 -1.59248651\n",
      "  -0.89683016 -0.11764291 -0.48189987  0.         -0.30914351  0.\n",
      "  -0.42008403 -0.57735027 -0.33333333  1.36277029 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]\n",
      " [ 0.81649658 -1.          0.68074565 -0.13018891 -0.90453403  0.74535599\n",
      "  -0.15369466 -1.13898959 -0.5         1.15082516  1.13257616  0.21576323\n",
      "   0.56825131  0.46479771 -0.18304938 -0.45964892 -0.41370176 -0.12554609\n",
      "  -0.35805744  0.57447443 -0.32597162 -0.48572846  0.57777944 -0.32347415\n",
      "  -0.48839039 -1.09880274 -0.48189987  0.         -0.53027621  0.\n",
      "  -0.42008403 -0.57735027  3.         -0.73379939 -0.42008403 -0.33333333\n",
      "  -1.22474487  0.          1.73205081 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]\n",
      " [ 0.81649658  1.         -0.03582872 -1.43207802 -0.90453403 -0.74535599\n",
      "  -0.15369466  0.2847474   2.         -0.17632082 -0.21002047 -0.29191496\n",
      "  -0.31275847 -0.30093163 -0.18304938 -0.82736805 -0.70920301 -0.12554609\n",
      "  -0.35805744  0.26799132  1.27628284  1.17589238  0.27569555  1.30408413\n",
      "   1.23113526 -0.14868474 -0.48189987  0.         -0.08801081  0.\n",
      "  -0.42008403 -0.57735027 -0.33333333  1.36277029 -0.42008403 -0.33333333\n",
      "  -1.22474487  0.          1.73205081 -0.42008403  1.73205081 -0.81649658\n",
      "  -0.5        -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]\n",
      " [ 0.81649658 -1.          0.68074565  1.1717002  -0.04307305 -0.248452\n",
      "  -0.15369466 -0.1898316  -0.5         0.82851828  0.80651698  0.21576323\n",
      "   0.56825131  0.40353936 -0.18304938 -0.09192978 -0.1182005   1.54840181\n",
      "  -0.35805744  0.69754831 -0.09738667 -0.32808118  0.69908673 -0.09127923\n",
      "  -0.32524935  0.92021503 -0.48189987  0.         -0.677698    0.\n",
      "  -0.42008403 -0.57735027 -0.33333333  1.36277029 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403 -0.57735027 -0.81649658\n",
      "   2.         -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]\n",
      " [-1.22474487  1.         -0.03582872 -0.13018891 -0.04307305  0.248452\n",
      "   0.87093638  0.2847474  -0.5         0.16494529  0.13521866  0.21576323\n",
      "   0.56825131  0.28102267  1.03727979  2.11438502  1.95030829  1.54840181\n",
      "   1.07417231 -0.17743191 -1.19976502 -0.84475868 -0.16333415 -1.21106705\n",
      "  -0.85993223  1.06477116 -0.48189987  0.          2.86042514  0.\n",
      "  -0.42008403 -0.57735027 -0.33333333 -0.73379939  2.38047614 -0.33333333\n",
      "  -1.22474487  0.          1.73205081 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573  3.         -1.1055416   0.         -0.65465367\n",
      "   0.        ]\n",
      " [-1.22474487  1.          0.68074565 -0.13018891 -0.90453403  0.74535599\n",
      "   0.87093638 -0.1898316  -0.5         0.01327146 -0.01822095  0.21576323\n",
      "   0.27458138  0.25039349 -0.18304938  0.27578935  0.17730075 -0.96252004\n",
      "  -1.79028719  1.49036852  0.61627432  0.33416022  1.48052693  0.63365234\n",
      "   0.36007009 -0.62682704 -0.48189987  0.         -0.08801081  0.\n",
      "   2.38047614 -0.57735027 -0.33333333 -0.73379939 -0.42008403  3.\n",
      "  -1.22474487  0.         -0.57735027 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]\n",
      " [ 0.81649658 -1.         -0.03582872 -0.13018891 -0.04307305 -0.248452\n",
      "  -0.66601018 -0.6644106  -0.5        -0.70717922 -0.74705913 -0.64094372\n",
      "  -0.72389637 -0.68379629 -0.91524688 -1.04799953 -1.06380452  1.54840181\n",
      "   1.07417231 -0.34239091 -1.27800411 -0.85806937 -0.32592536 -1.29054174\n",
      "  -0.87370678  1.06477116 -0.48189987  0.          1.97589435  0.\n",
      "  -0.42008403  1.73205081 -0.33333333 -0.73379939 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573 -0.33333333 -1.1055416   0.          1.52752523\n",
      "   0.        ]\n",
      " [ 0.81649658  1.         -0.03582872  1.1717002   0.81838794 -1.73916398\n",
      "  -0.15369466  1.23390539 -0.5        -0.65030153 -0.68951927 -0.51402417\n",
      "  -0.5770614  -0.54596501 -0.67118104  0.64350849  0.35460151 -0.96252004\n",
      "   1.07417231 -0.69229323 -0.09012347 -0.32263879 -0.67080523 -0.08390133\n",
      "  -0.31961731  1.06521617  0.89495691  0.         -1.56222879  0.\n",
      "  -0.42008403  1.73205081 -0.33333333 -0.73379939 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573 -0.33333333 -1.1055416   0.          1.52752523\n",
      "   0.        ]\n",
      " [ 0.81649658 -1.         -0.03582872 -0.13018891 -0.04307305  0.74535599\n",
      "   0.35862086 -0.6644106  -0.5         0.39245603  0.36537808 -0.57748395\n",
      "  -0.72389637 -0.65316712 -1.15931271 -0.82736805 -0.94560402 -0.96252004\n",
      "   1.07417231  1.76884469 -0.31019117 -0.47569445  1.75500589 -0.30744447\n",
      "  -0.47800671 -1.05817045 -0.48189987  0.          0.10658596  0.\n",
      "  -0.42008403 -0.57735027 -0.33333333 -0.73379939  2.38047614 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403 -0.57735027  1.22474487\n",
      "  -0.5        -0.22941573 -0.33333333 -1.1055416   0.          1.52752523\n",
      "   0.        ]\n",
      " [ 0.81649658 -1.         -2.90212617 -2.73396713  1.67984892 -0.248452\n",
      "   0.35862086  0.2847474  -0.5        -0.53654616 -0.57443956 -0.48229428\n",
      "  -0.45959343 -0.46939208 -0.67118104  0.27578935  0.05910025  0.71142786\n",
      "   1.07417231  0.07326738 -0.69263788 -0.68341058  0.08376664 -0.69593103\n",
      "  -0.69296141  1.0663514   0.89495691  0.          0.43238813  0.\n",
      "  -0.42008403  1.73205081 -0.33333333 -0.73379939 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403  1.73205081 -0.81649658\n",
      "  -0.5        -0.22941573 -0.33333333 -1.1055416   0.          1.52752523\n",
      "   0.        ]\n",
      " [ 0.81649658  1.         -0.03582872 -1.43207802 -0.90453403  0.248452\n",
      "  -3.73990329  1.70848439 -0.5        -0.55550539 -0.59361951 -0.54575406\n",
      "  -0.6064284  -0.57659419  2.25760896  0.64350849  1.06380452  0.71142786\n",
      "   1.07417231 -0.03160656 -0.34494995 -0.49762901 -0.01960196 -0.34275219\n",
      "  -0.50070566  0.01231865  0.89495691  0.         -0.8251198   0.\n",
      "  -0.42008403  1.73205081 -0.33333333 -0.73379939 -0.42008403 -0.33333333\n",
      "  -1.22474487  0.         -0.57735027 -0.42008403  1.73205081 -0.81649658\n",
      "  -0.5        -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]\n",
      " [-1.22474487 -1.         -0.03582872  1.1717002   0.81838794  0.74535599\n",
      "  -0.15369466 -1.13898959 -0.5        -0.19528005 -0.22920042 -0.4505644\n",
      "  -0.45959343 -0.45407749 -0.91524688 -1.12154336 -1.12290477  0.71142786\n",
      "   1.07417231 -1.00181847  0.61501638  0.3327663  -0.97588759  0.63237454\n",
      "   0.35862759  1.86382133  3.64867047  0.          1.00880736  0.\n",
      "  -0.42008403  1.73205081 -0.33333333 -0.73379939 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403  1.73205081 -0.81649658\n",
      "  -0.5        -0.22941573 -0.33333333 -1.1055416   0.          1.52752523\n",
      "   0.        ]\n",
      " [-1.22474487  1.          0.68074565 -0.13018891 -0.90453403  0.248452\n",
      "   0.87093638  0.2847474  -0.5        -0.65030153 -0.40181999 -0.51402417\n",
      "  -0.6064284  -0.5612796  -0.67118104 -0.45964892 -0.53190226  0.71142786\n",
      "  -1.79028719  0.60901306 -0.63885709 -0.65867097  0.6118223  -0.6413009\n",
      "  -0.66735966  1.06623334 -0.48189987  0.          0.88202462  0.\n",
      "   2.38047614 -0.57735027 -0.33333333 -0.73379939 -0.42008403 -0.33333333\n",
      "   0.81649658  0.         -0.57735027 -0.42008403 -0.57735027 -0.81649658\n",
      "   2.         -0.22941573 -0.33333333  0.90453403  0.         -0.65465367\n",
      "   0.        ]] 7     NaN\n",
      "8     NaN\n",
      "9     NaN\n",
      "10    NaN\n",
      "11    9.9\n",
      "12    NaN\n",
      "13    NaN\n",
      "14    NaN\n",
      "15    NaN\n",
      "16    NaN\n",
      "17    NaN\n",
      "18    NaN\n",
      "19    NaN\n",
      "Name: migration_m, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-765310b14204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import ShuffleSplit, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    " \n",
    "X = scaled_features\n",
    "Y = target\n",
    "names = features.columns.values\n",
    "\n",
    "print(np.any(np.isnan(X)))\n",
    "print(np.any(np.isnan(Y)))\n",
    "print(np.all(np.isfinite(X)))\n",
    "print(np.all(np.isfinite(Y)))\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    " \n",
    "#crossvalidate the scores on a number of different random splits of the data\n",
    "for train_idx, test_idx in KFold(len(X)):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "    print(X_train, Y_train)\n",
    "    r = rf.fit(X_train, Y_train)\n",
    "    acc = r2_score(Y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(Y_test, rf.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted([(round(np.mean(score), 4), feat) for\n",
    "              feat, score in scores.items()], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-35.870204999999999"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, scaled_features, target, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-72.7652613495\n",
      "-108.307860866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "print(cross_val_score(lr, scaled_features, target, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "print(cross_val_score(lr, features, target, cv=5, scoring='neg_mean_squared_error').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.99667119707285"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVR_rbf, scaled_features, target, cv=5, scoring='neg_mean_squared_error').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.679414172227485"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVR_rbf, features, target, cv=5, scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
